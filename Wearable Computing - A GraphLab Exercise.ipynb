{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wearable Computing\n",
    "## A Dato GraphLab Exercise for AccelOne\n",
    "### Author: Matthew Bird"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Resources: \n",
    "\n",
    "- [Presentation from SBiA][df1]\n",
    "\n",
    "- [CSV data file][df2]\n",
    "[df1]: <http://groupware.les.inf.puc-rio.br/public/2012.SBIA.Ugulino.WearableComputing-Presentation.pdf>\n",
    "[df2]: <http://groupware.les.inf.puc-rio.br/static/har/dataset-har-PUC-Rio-ugulino.zip>\n",
    "\n",
    "##Problem Statement:\n",
    "\n",
    "- The overriding design goal for this project is to use the Dato GraphLab framework to produce a machine learning classifier capable of identifying human kinetic behavior from sensors attached to a person. The above mentioned Presentation and Data will be used for the purpose of this Notebook.\n",
    "\n",
    "## Outline:\n",
    "\n",
    "- 1.Load and Explore dataset\n",
    "- 2.Transform dataset into usable format\n",
    "- 3.Visualize data using Dato GraphLab\n",
    "- 4.Generate preliminary models using Dato GraphLab\n",
    "- 5.Feature Engineering\n",
    "- 6.Generate and tune a final model\n",
    "- 7.Examine Feature Space\n",
    "- 8.Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##1. Load and Explore dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ####Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import graphlab as gl\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "gl.canvas.set_target('ipynb')\n",
    "gl.canvas.set_target('browser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ####Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = 'data/dataset-har-PUC-Rio-ugulino.csv'\n",
    "df = pd.read_csv (file_path, delimiter =\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##2. Transform dataset into usable format:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ####Function for transforming data\n",
    "  -Remove single bad data point\n",
    "  \n",
    "  -Converts data to useable types\n",
    "  \n",
    "  -Convert metric commas into decimals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_data(data_frame):\n",
    "    \"\"\"\n",
    "    Accepts a DataFrame object\n",
    "    Returns modified DataFrame object\n",
    "    \"\"\"\n",
    "    data_frame = data_frame.drop(data_frame.index[[122076]]) #bad data point needs removal\n",
    "    for col in ['user', 'gender', 'class']:\n",
    "        data_frame[col] = data_frame[col].astype(str)\n",
    "    for col in ['age', 'weight', 'x1', 'x2', 'x3', 'x4', 'y1', 'y2', 'y3', 'y4', 'z1', 'z2', 'z3', 'z4']:\n",
    "        data_frame[col] = data_frame[col].astype(int)\n",
    "    for col in ['how_tall_in_meters', 'body_mass_index']:\n",
    "        data_frame[col] = data_frame[col].apply(lambda x: str(x).replace(\".\",\"\").replace(\",\",\".\"))\n",
    "        data_frame[col] = data_frame[col].astype(float)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = transform_data(df)\n",
    "sf = gl.SFrame(data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##3. Visualize data using Dato GraphLab:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ####Using GraphLab Visualization we can see that our data includes 18 features\n",
    "  - **5 User metrics** (Name, Gender, Age, Height, BMI)  \n",
    "  - **12 sensor readings** (x1, y1, z1, x2, y2, z2, x3, y3, z3, x4, y4, z4)\n",
    "  - **1 Class** - Prediction target - (sitting, standing, walking, standingup, sittingdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canvas is accessible via web browser at the URL: http://localhost:36784/index.html\n",
      "Opening Canvas in default web browser.\n"
     ]
    }
   ],
   "source": [
    "sf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##4. Generate preliminary models using Dato GraphLab:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ####The GraphLab general classifier discovers that GradientBoostedTrees look promising with the highest accuracy of 97%\n",
    "  - BoostedTreesClassifier          : **0.976342788171**\n",
    "  - RandomForestClassifier          : 0.945443572722\n",
    "  - LogisticClassifier              : 0.837417"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n",
      "PROGRESS: The following methods are available for this type of problem.\n",
      "PROGRESS: BoostedTreesClassifier, RandomForestClassifier, LogisticClassifier\n",
      "PROGRESS: The returned model will be chosen according to validation accuracy.\n",
      "PROGRESS: Boosted trees classifier:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 157479\n",
      "PROGRESS: Number of classes           : 5\n",
      "PROGRESS: Number of feature columns   : 18\n",
      "PROGRESS: Number of unpacked features : 18\n",
      "PROGRESS: Starting Boosted Trees\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS:   Iter      Accuracy          Elapsed time\n",
      "PROGRESS:         (training) (validation)\n",
      "PROGRESS:      0   9.358e-01   9.378e-01        0.34s\n",
      "PROGRESS:      1   9.447e-01   9.425e-01        0.69s\n",
      "PROGRESS:      2   9.571e-01   9.529e-01        0.98s\n",
      "PROGRESS:      3   9.632e-01   9.604e-01        1.29s\n",
      "PROGRESS:      4   9.673e-01   9.654e-01        1.62s\n",
      "PROGRESS:      5   9.700e-01   9.687e-01        1.96s\n",
      "PROGRESS:      6   9.728e-01   9.715e-01        2.26s\n",
      "PROGRESS:      7   9.752e-01   9.746e-01        2.57s\n",
      "PROGRESS:      8   9.776e-01   9.767e-01        2.84s\n",
      "PROGRESS:      9   9.790e-01   9.790e-01        3.14s\n",
      "PROGRESS: Random forest classifier:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 157479\n",
      "PROGRESS: Number of classes           : 5\n",
      "PROGRESS: Number of feature columns   : 18\n",
      "PROGRESS: Number of unpacked features : 18\n",
      "PROGRESS: Starting Boosted Trees\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS:   Iter      Accuracy          Elapsed time\n",
      "PROGRESS:         (training) (validation)\n",
      "PROGRESS:      0   9.363e-01   9.345e-01        0.31s\n",
      "PROGRESS:      1   9.431e-01   9.410e-01        0.55s\n",
      "PROGRESS:      2   9.434e-01   9.428e-01        0.80s\n",
      "PROGRESS:      3   9.476e-01   9.470e-01        1.04s\n",
      "PROGRESS:      4   9.485e-01   9.475e-01        1.32s\n",
      "PROGRESS:      5   9.497e-01   9.476e-01        1.61s\n",
      "PROGRESS:      6   9.497e-01   9.460e-01        1.82s\n",
      " PROGRESS:      7   9.496e-01   9.458e-01        2.04s\n",
      "PROGRESS:      8   9.489e-01   9.458e-01        2.34s\n",
      "PROGRESS:      9   9.488e-01   9.454e-01        2.55s\n",
      "PROGRESS: Logistic regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 157479\n",
      "PROGRESS: Number of classes           : 5\n",
      "PROGRESS: Number of feature columns   : 18\n",
      "PROGRESS: Model selection based on validation accuracy:\n",
      "PROGRESS: ---------------------------------------------\n",
      "PROGRESS: BoostedTreesClassifier          : 0.979026125353\n",
      "PROGRESS: RandomForestClassifier          : 0.945418864222\n",
      "PROGRESS: LogisticClassifier              : 0.835398\n",
      "PROGRESS: ---------------------------------------------\n",
      "PROGRESS: Selecting BoostedTreesClassifier based on validation set performance.\n",
      "PROGRESS: Number of unpacked features : 18\n",
      "PROGRESS: Number of coefficients    : 84\n",
      "PROGRESS: Starting Newton Method\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: +-----------+----------+--------------+-------------------+---------------------+\n",
      "PROGRESS: | Iteration | Passes   | Elapsed Time | Training-accuracy | Validation-accuracy |\n",
      "PROGRESS: +-----------+----------+--------------+-------------------+---------------------+\n",
      "PROGRESS: | 1         | 2        | 0.463771     | 0.795833          | 0.797988            |\n",
      "PROGRESS: | 2         | 3        | 0.720082     | 0.821481          | 0.827180            |\n",
      "PROGRESS: | 3         | 4        | 0.977213     | 0.827088          | 0.830737            |\n",
      "PROGRESS: | 4         | 5        | 1.229795     | 0.829692          | 0.832209            |\n",
      "PROGRESS: | 5         | 6        | 1.501069     | 0.831762          | 0.833681            |\n",
      "PROGRESS: | 6         | 7        | 1.751337     | 0.832492          | 0.835030            |\n",
      "PROGRESS: | 10        | 11       | 2.796580     | 0.832962          | 0.835398            |\n",
      "PROGRESS: +-----------+----------+--------------+-------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "model = gl.classifier.create(sf, target='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ####We can go on to show that the model only uses 10 or so of features for the majority of its classification\n",
    "  \n",
    "  -Things like age, gender, and BMI show little utility and land to the right-hand side of the following graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff89c1e8c90>]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEACAYAAAC57G0KAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHTVJREFUeJzt3XmcVOWd7/HPTxAUmQmigiDtCxSI4K4IGBfKBQXNAJq4\nRRMUzctJNCEmuQmYTGjunRj0uiQTlxnjMpgASlwQXGm8lFsG0bgiIcgoQquAqCjioN3yu388p+2i\n7b2r6qnl+369+tWnT9ep+rH0t57+nec8x9wdEREpPTvELkBERHJDAS8iUqIU8CIiJUoBLyJSohTw\nIiIlSgEvIlKimg14M9vJzJ4xsxfNbLmZ/SbZ39PMqsxspZktNLMeGcdMNbPXzGyFmZ2U6z+AiIg0\nzlqaB29m3dz9EzPrDDwF/BQYB2x096vM7OfAru4+xcyGArOBI4C9gEXAYHffltM/hYiIfEmLLRp3\n/yTZ7AJ0Aj4gBPzMZP9MYEKyPR6Y4+417r4aWAUMz2bBIiLSOi0GvJntYGYvAuuBxe7+KtDb3dcn\nD1kP9E62+wLVGYdXE0byIiKSZ51bekDSXjnEzL4CPGpmxzX4vptZc30erYUgIhJBiwFfx90/NLMH\ngcOB9Wa2p7uvM7M+wIbkYW8BFRmH9Uv2baeFNwQREWmCu1trH9vSLJrd62bImNnOwGjgBWA+MDF5\n2ERgXrI9HzjbzLqY2QBgELC0iSIL/mPatGnRayiVOouhRtWpOgv9o61aGsH3AWaa2Q6EN4M/uvtj\nZvYCMNfMLgRWA2cmob3czOYCy4Fa4PvenqpERKTDmg14d38FOKyR/e8DJzZxzBXAFVmpTkRE2i3a\nlawvvRTrlVsvlUrFLqFViqHOYqgRVGe2qc64WrzQKScvauYjRjhPPw2dOuX95UVEipKZ4dk6yZpL\nO+4I//EfsV5dRKT0RRvBv/qqM2pUaNX07Zv3EkREik5bR/DRAt7d+eUvYeVKmDs37yWIiBSdomnR\nAPziF/D88/DggzGrEBEpTVEDfued4aab4JJLYMuWmJWIiJSeqC2aOuedF/rwV12V91JERIpGUfXg\n62zYAAccAFVVcPDBeS9HRKQoFFUPvk6vXnDFFXDxxfD557GrEREpDQUR8ACTJmluvIhINhVEi6bO\n8uVobryISBOKsgefSXPjRUQaV5Q9+EyaGy8ikh0FF/CaGy8ikh0F16Kpo7nxIiLbK/oefB3NjRcR\n2V7R9+DraG68iEjHFGzAg+bGi4h0RMG2aOpobryISFAyPfhMmhsvIlJCPfhMmhsvItJ2RRHwmhsv\nItJ2RdGiqaO58SJSzkqyB19Hc+NFpJyVZA++jubGi4i0XlEFPGhuvIhIaxVVi6aO5saLSDnKaovG\nzCrMbLGZvWpmy8zsh8n+SjOrNrMXko+xGcdMNbPXzGyFmZ3U/j9K04YODW2aH/0oF88uIlIamh3B\nm9mewJ7u/qKZdQf+CkwAzgQ2u/u1DR4/FJgNHAHsBSwCBrv7tgaP69AIHuB//gcOPBB+9zs49dQO\nPZWISFHI6gje3de5+4vJ9sfA3wjBDdDYi4wH5rh7jbuvBlYBw1tbTFtobryISPNafZLVzPoDhwJL\nkl0/MLOXzOxWM+uR7OsLVGccVk39G0LWjR4NRx8N06fn6hVERIpXqwI+ac/cDUxORvI3AQOAQ4B3\ngGuaOTynZ3GvvRb+8z/DcgZPPw21tbl8NRGR4tG5pQeY2Y7APcCf3H0egLtvyPj+LcCC5Mu3gIqM\nw/sl+76ksrLyi+1UKkUqlWpb5YleveCxx2D27NCuWbMmjOzHjoWTT4Y+fdr1tCIi0aXTadLpdLuP\nb+kkqwEzgffc/bKM/X3c/Z1k+zLgCHf/VsZJ1uHUn2Qd2PCMajZOsjbl7bfhkUfg4Ydh0SLo3z+E\n/dixcOSR0LnFtzQRkcKU1aUKzOxo4AngZepbLZcD5xDaMw68AVzs7uuTYy4HJgG1hJbOo408b84C\nPlNtLSxZEsL+4YfhjTfghBNC2I8ZA3vl7OyAiEj2lfRaNB21bh08+mgI+6oq6NevPuyPOipcISsi\nUqgU8K1UWwtLl9aP7letguOPrw/8ioqWn0NEJJ8U8O20YUP96H7hwnBy9pJL4IILoGvX2NWJiCjg\ns+Lzz8OUyxkzYNkymDo1LHKmoBeRmEp6ueB86dQJjj0WHnoI/vxnWLAABg6EG2+ETz+NXZ2ISOso\n4FswYkQI+nvuCZ8HDoQbboCtW2NXJiLSPAV8Kw0fDg88APfeG+bZDxwI11+voBeRwqWAb6Mjjggt\nm3nzwsnYgQPh3/4trG4pIlJIFPDtNGwYzJ8P998flkoYODAsXaygF5FCoYDvoMMPDyG/YAEsXgz7\n7gu//a2CXkTiU8BnyWGHhbbNgw/C44+HoL/uOvjkk9iViUi5UsBn2aGHwn33hRk3Tz4Zgv7aaxX0\nIpJ/CvgcOeSQ+hk3Tz8N++wDV18N770XuzIRKRcK+Bw7+OAwh37hQnj++RD048bBXXdpVC8iuaWl\nCvLso49CC2fWLHj22RD2554bFjrTWvUi0hytRVNE1q2DO+8MYV9dDWedFcJ+2DCwVv8Tiki5UMAX\nqZUrQ9DPmhXWwvnWt0LYDxwYuzIRKRQK+CLnHtapnzUr9On79w9Bf9ZZ0Lt37OpEJCYFfAmprQ1X\nyc6aFa6aHTkyhP1pp0H37rGrE5F8U8CXqC1bQsjPmgVPPRXuPHXuuXDyybrVoEi5UMCXgY0bYe7c\nEParVsEvfwn//M8KepFSp4AvM6+8Aj/+cZiFc+21YWQvIqVJAV+G3MMaOD/5CQwYANdcA/vvH7sq\nEck23bKvDJnB178eRvNjx0IqFW4YvnFj7MpEJCYFfAnp0gUmT4YVK8Jc+iFDwoqWn30WuzIRiUEB\nX4J22y3cZeqJJ6CqCg44IMzAUVdMpLyoB18GHnkknIjt2zeciD3ooNgViUh7qAcvXzJmDLz8crhA\navRouPhi2LAhdlUikmsK+DLRuXM48bpiBeyyCwwdClddBZ9+GrsyEckVBXyZ2XXX0Kb5y1/CjUiG\nDg3r1atjJlJ6mg14M6sws8Vm9qqZLTOzHyb7e5pZlZmtNLOFZtYj45ipZvaama0ws5Ny/QeQ9hk8\nONws/OabYfr0MLXy+edjVyUi2dTSCL4GuMzd9wdGApeY2RBgClDl7oOBx5KvMbOhwFnAUGAMcKOZ\n6beEAnbCCfDCC2Fdm1NOgUmT4J13YlclItnQplk0ZjYPuD75GOXu681sTyDt7vuZ2VRgm7tfmTz+\nEaDS3Zc0eB7NoilAH34IV1wB118P3bpBz57bf+y2W/P7vvIV2EFv5yI5k7OlCsysP/A4cACwxt13\nTfYb8L6772pmvweWuPus5Hu3AA+7+z0NnksBX8BqauCDD+D998NNwt9/f/uPpvZt2QI9ejT+JjBk\nSJi9oztVibRfWwO+VXcBNbPuwD3AZHffbBk/pe7uZtZcWjf6vcrKyi+2U6kUqVSqNaVIHuy4I/Tq\nFT7aoqYGNm1q/I3ghhvCjJ3Jk3NTs0gpSqfTpNPpdh/f4gjezHYEHiCMxH+b7FsBpNx9nZn1ARYn\nLZopAO4+I3ncI8A0d3+mwXNqBF9m3ngDjjwS5syB446LXY1IccrqhU5J++VWYHlduCfmAxOT7YnA\nvIz9Z5tZFzMbAAwClra2GCldAwaE9evPOQdWr45djUh5aHYEb2ZHA08AL1PfaplKCO25wN7AauBM\nd9+UHHM5MAmoJbR0Hm3keTWCL1PXXQd33BHm4HfrFrsakeKi9eCloLnDd74Dn38eRvQ66SrSelqL\nRgqaWbi46u9/D1fUikjuaAQvUaxZAyNGhHbN6NGxqxEpDhrBS1HYe2+480447zx4/fXY1YiUJgW8\nRDNqFPzLv8CECeEiKRHJLrVoJCr3sP7Nli1w11066SrSHLVopKiYwU03hbnxV14ZuxqR0qIRvBSE\n6upw0vWWW2Ds2NjViBQmzYOXovX003D66fDUUzBoUOxqRAqPWjRStI46Ktx8ZMIE2Lw5djUixU8j\neCko7mFZ4Y0b4e67tb68SCaN4KWomcHvfw/r1oWbj4hI+7VqPXiRfOraNdwI/Igj4OCD4Z/+KXZF\nIsVJLRopWEuWwLhx8OST8NWvxq5GJD61aKRkjBwZ2jTjx4f7xYpI22gELwXvkktg7VqYN08nXaW8\naQQvJee668JNwKdPj12JSHFRwEvB69IlTJm8/Xa4777Y1YgUD7VopGg8+yyceiqk0zB0aOxqRPJP\nLRopWUccAVdfHa503bQpdjUihU8jeCk6kyfDa6/BggXQqVPsakTyR4uNScmrqYGTToIBA8LiZAMH\nhu2uXWNXJpJbCngpCxs3wq9/HW7e/dprYRplnz4h7AcNCp/rtgcMgJ12il2xSMcp4KUs1dTAm2/C\nqlUh8Fetqt9+803Yc8/64M98A9h3X4W/FA8FvEgDtbXNh3+vXvXBP3o0fPObsSsWaZwCXqQNamth\nzZr6wL/6avjZz+B734tdmciXKeBFOuD11yGVgsrKcDNwkULS1oDXcsEiGfbZBxYtguOOC7Nyzj03\ndkUi7aeAF2lg8GBYuBBOPDEsk3DGGbErEmmfFq9kNbPbzGy9mb2Ssa/SzKrN7IXkY2zG96aa2Wtm\ntsLMTspV4SK5tP/+8MgjcOmlMH9+7GpE2qfFHryZHQN8DNzh7gcm+6YBm9392gaPHQrMBo4A9gIW\nAYPdfVuDx6kHL0XhuefglFPgjjtgzJjY1Ui5y/paNO7+JPBBY6/VyL7xwBx3r3H31cAqYHhrixEp\nNMOGwf33w7e/DY89FrsakbbpyGJjPzCzl8zsVjPrkezrC1RnPKaaMJIXKVpHHhnuEXvOOeH2gSLF\nor0nWW8C/ney/X+Aa4ALm3hso72YysrKL7ZTqRSpVKqdpYjk3rHHwuzZ8I1vhJ78yJGxK5JykE6n\nSafT7T6+VfPgzaw/sKCuB9/U98xsCoC7z0i+9wgwzd2faXCMevBSlB56CM4/Hx5+GA4/PHY1Um7y\nsh68mfXJ+PI0oG6GzXzgbDPrYmYDgEHA0va8hkghOuUUuPnmcOORl1+OXY1I81ps0ZjZHGAUsLuZ\nrQWmASkzO4TQfnkDuBjA3Zeb2VxgOVALfF9DdSk1EybAZ5+FWTWPPQZDhsSuSKRxWqpApJ3+9CeY\nMgUWLw4LlYnkmpYqEMmT886DTz+FE06Axx8P686LFBIFvEgHXHjh9iFfURG7IpF6CniRDvr+90PI\nH388PPFEuLOUSCFQwItkwWWXwdatYSSfToebiIjEpoAXyZKpU8NI/sQTw4nX3XaLXZGUO82iEcki\n9xD0VVVhCmWPHi0fI9JauqOTSGTuoWWzZElYV/4f/zF2RVIqFPAiBcA9nHxdtiysK7/LLrErklKQ\nl6UKRKR5ZnDDDeHuUF/7GixYEEJfJJ80ghfJoW3bwnry06dDp07wq1/BuHHhDUCkrdSiESlA27aF\nZYanTw/h/qtfwfjxCnppGwW8SAFzrw/6bdtg2rQQ9DuoWSqtoIAXKQLuoS8/fTrU1oagnzBBQS/N\nU8CLFBF3eOCBEPSffRZaN6efrqCXxingRYqQOzz4YAj6rVtD0H/jGwp62Z4CXqSIuYfbAVZWwief\nhKD/5jcV9BIo4EVKgHu4QKqyEj7+uD7oO3WKXZnEpIAXKSHu8OijIeg/+igE/RlnKOjLlQJepAS5\nh3VtKith0ya49NKw/vx++2kufTlRwIuUMPewUuWcOWHd+U8+gVQKRo0Kn4cMUeCXMgW8SBlZvTrc\nKjCdDp+3bAlhXxf4Q4cq8EuJAl6kjL355vaBv3kzHHtsCPu6wNeMnOKlgBeRL6xZs33gf/jh9oG/\n//4K/GKigBeRJq1du33gf/BBfeCfcw7ssUfsCqU5CngRabXq6hD0c+dC167hsxQuBbyItNmmTdC/\nP6xaBbvvHrsaaYru6CQibdajR7gRyR//GLsSySYFvIgAcNFFcMsturVgKWkx4M3sNjNbb2avZOzr\naWZVZrbSzBaaWY+M7001s9fMbIWZnZSrwkUku445BmpqYMmS2JVItrRmBH87MKbBvilAlbsPBh5L\nvsbMhgJnAUOTY240M/2WIFIEzOpH8VIaWgxfd38S+KDB7nHAzGR7JjAh2R4PzHH3GndfDawChmen\nVBHJtYkT4d57w8JmUvzaO7ru7e7rk+31QO9kuy9QnfG4amCvdr6GiORZ795hEbO77opdiWRD544+\ngbu7mTV3WqbR71VWVn6xnUqlSKVSHS1FRLLgoovCqpXf/W7sSiSdTpNOp9t9fKvmwZtZf2CBux+Y\nfL0CSLn7OjPrAyx29/3MbAqAu89IHvcIMM3dn2nwfJoHL1KgPv88zIl/8EE46KDY1UimfM2Dnw9M\nTLYnAvMy9p9tZl3MbAAwCFjaztcQkQg6dYJJk+DWW2NXIh3V4gjezOYAo4DdCf32XwH3A3OBvYHV\nwJnuvil5/OXAJKAWmOzujzbynBrBixSw1ath2LCwlMFOO8WuRupoqQIRyYqTT4bzzw+LkElh0FIF\nIpIVmhNf/DSCF5FGffopVFTAf/0X7Ltv7GoENIIXkSzp2hW+/W247bbYlUh7aQQvIk1avhxOPDHc\nGapzh6+akY7SCF5EsmboUBgwAB5+OHYl0h4KeBFplk62Fi+1aESkWR9/DHvvDcuWQd++saspb2rR\niEhWde8OZ5wBM2e2/FgpLBrBi0iLnn02XPC0ciXsoGFhNBrBi0jWDRsGu+wCjz8euxJpCwW8iLRI\nd3sqTmrRiEirvP8+7LMPvP469OwZu5rypBaNiOREz55w6qkwa1bsSqS1FPAi0moXXQR/+APoF/Di\noIAXkVYbNQo++QSeey52JdIaCngRabUddoALL9TJ1mKhk6wi0iZvvw0HHBAWIOvePXY15UUnWUUk\np/r2hWOOgT//OXYl0hIFvIi0mebEFwcFvIi02dix4cbcy5fHrkSao4AXkTbr3DnckPvWW2NXIs3R\nSVYRaZf//m848khYuzbc3k9yTydZRSQv9t0XDjwQ5s+PXYk0RQEvIu2mk62FTS0aEWm3rVuhX79w\nZWv//rGrKX1q0YhI3uy0E5x7Ltx+e+xKpDEawYtIh7z8clhlcvVq6NQpdjWlTSN4Ecmrgw4KV7cu\nXBi7EmmoQwFvZqvN7GUze8HMlib7eppZlZmtNLOFZtYjO6WKSKHSydbC1KEWjZm9ARzu7u9n7LsK\n2OjuV5nZz4Fd3X1Kg+PUohEpIZs3w957w4oV0Lt37GpKV4wWTcMXGwfMTLZnAhOy8BoiUsD+4R/g\n9NPhjjtiVyKZOhrwDiwys+fM7LvJvt7uvj7ZXg/o/VykDNS1afTLeeHo3MHjj3L3d8xsD6DKzFZk\nftPd3cz0zy1SBkaODGvUPPVUWE5Y4utQwLv7O8nnd83sPmA4sN7M9nT3dWbWB9jQ2LGVlZVfbKdS\nKVKpVEdKEZHIzOpH8Qr47Ein06TT6XYf3+6TrGbWDejk7pvNbBdgITAdOBF4z92vNLMpQA+dZBUp\nDxs3wsCBYU58D82fy7p8nmTtDTxpZi8CzwAPuPtCYAYw2sxWAscnX4tIGdh9dzj5ZJgzJ3YlArqS\nVUSyrKoKpkyBv/41diWlR1eyikhUJ5wA770Hzz8fuxJRwItIVu2wA1x4oa5sLQRq0YhI1q1dCwcf\nDNXV0K1b7GpKh1o0IhJdRUW4nd/UqfDxx7GrKV8KeBHJiX//d3j3XRg0CG64AT77LHZF5UcBLyI5\nUVEBs2fDQw/BAw/AkCHh623bYldWPtSDF5G8SKfD9MmtW+E3v4ExY8LVr9J6be3BK+BFJG/cYd48\nuPxy6NULZswIvXppHZ1kFZGCZQannQavvAITJ8KZZ8KECbB8eezKSpMCXkTyrnNnmDQJVq6Eo4+G\nVAouuADWrIldWWlRwItINDvvDD/9aQj6vn3hkEPgxz8Oi5ZJxyngRSS6Hj3g17+GV18NJ2H32w/+\n9V81h76jFPAiUjD69IEbb4QlS0LYaw59xyjgRaTgDBwYlhx+6CFYsEBz6NtL0yRFpOAtXhzm0H/6\naZiF068f7LVX+OjXL7R4ymFOvebBi0hJcg9XxD7zDLz1Vviorg6fa2rqwz4z+DO3e/cOs3eKmQJe\nRMrO5s31oZ8Z/Jnb770He+yxffDXhf8BB4SPQn8DUMCLiDSipgbeeefLbwRr18JLL4XPhx4KI0aE\nj+HDYe+9C6v1o4AXEWmHTZvguedCC2jp0vAZ6sN+xAgYNizuzcQV8CIiWeAerqytC/ulS8NtCCsq\n6gN/xAg48EDo0iU/NSngRURypLYWli3bPvRffz3cvSoz9AcMyE1rRwEvIpJHmzeH1k5d6D/zTLgw\na9GiEPzZpIAXEYnsrbdgt91gp52y+7wKeBGREqX14EVEBFDAi4iULAW8iEiJUsCLiJSonAS8mY0x\nsxVm9pqZ/TwXryEiIs3LesCbWSfgemAMMBQ4x8yGZPt18iGdTscuoVWKoc5iqBFUZ7apzrhyMYIf\nDqxy99XuXgPcCYzPwevkXLH8oxdDncVQI6jObFOdceUi4PcC1mZ8XZ3sExGRPMpFwOsKJhGRApD1\nK1nNbCRQ6e5jkq+nAtvc/cqMx+hNQESkHaIuVWBmnYG/AycAbwNLgXPc/W9ZfSEREWlW1m9Q5e61\nZnYp8CjQCbhV4S4ikn9RFhsTEZHcy+uVrMVwAZSZVZjZYjN71cyWmdkPY9fUHDPrZGYvmNmC2LU0\nxcx6mNndZvY3M1uenKcpOGY2Nfl3f8XMZptZ19g1AZjZbWa23sxeydjX08yqzGylmS00s4g3kvui\npsbq/L/Jv/tLZnavmX2l0GrM+N5PzGybmfWMUVuDWhqt08x+kPx9LjOzK5s6vk7eAr6ILoCqAS5z\n9/2BkcAlBVpnncnAcgp79tLvgIfcfQhwEFBwLTsz6w98FzjM3Q8ktBfPjllThtsJPzeZpgBV7j4Y\neCz5OrbG6lwI7O/uBwMrgal5r2p7jdWImVUAo4E3815R475Up5kdB4wDDnL3A4CrW3qSfI7gi+IC\nKHdf5+4vJtsfE8Kob9yqGmdm/YBTgFuAArr3e71kxHaMu98G4RyNu38YuazGfER4c++WTBToBrwV\nt6TA3Z8EPmiwexwwM9meCUzIa1GNaKxOd69y923Jl88A/fJe2Pb1NPZ3CXAt8LM8l9OkJur8HvCb\nJD9x93dbep58BnzRXQCVjOoOJfzHLETXAf8L2NbSAyMaALxrZreb2fNm9gcz6xa7qIbc/X3gGmAN\nYfbXJndfFLeqZvV29/XJ9nqgd8xiWmkS8FDsIhoys/FAtbu/HLuWFgwCjjWzJWaWNrNhLR2Qz4Av\n5BbCl5hZd+BuYHIyki8oZvZ1YIO7v0CBjt4TnYHDgBvd/TBgC4XRTtiOme0L/AjoT/iNrbuZnRu1\nqFZKbo9W0D9fZvYL4DN3nx27lkzJYONyYFrm7kjltKQzsKu7jyQM7Oa2dEA+A/4toCLj6wrCKL7g\nmNmOwD3An9x9Xux6mvA1YJyZvQHMAY43szsi19SYasLo6Nnk67sJgV9ohgF/cff33L0WuJfwd1yo\n1pvZngBm1gfYELmeJpnZ+YRWYiG+Ye5LeFN/KflZ6gf81cx6Ra2qcdWE/5ckP0/bzGy35g7IZ8A/\nBwwys/5m1gU4C5ifx9dvFTMz4FZgubv/NnY9TXH3y929wt0HEE4G/j93/07suhpy93XAWjMbnOw6\nEXg1YklNWQGMNLOdk/8DJxJOXheq+cDEZHsiUJADETMbQxhtjnf3rbHracjdX3H33u4+IPlZqiac\naC/EN8x5wPEAyc9TF3d/r7kD8hbwyaio7gKo5cBdBXoB1FHAecBxyfTDF5L/pIWukH9F/wEwy8xe\nIsyiuSJyPV/i7i8BdxAGInW92JvjVVTPzOYAfwG+amZrzewCYAYw2sxWEn7oZ8SsERqtcxLwe6A7\nUJX8LN1YIDUOzvi7zFQQP0dN1HkbsE8ydXIO0OKAThc6iYiUKN2yT0SkRCngRURKlAJeRKREKeBF\nREqUAl5EpEQp4EVESpQCXkSkRCngRURK1P8HPkSSI+O/tJ4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff89c392950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i_feats = model.get_feature_importance()\n",
    "f_imps = i_feats['count']\n",
    "plt.plot(f_imps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|      feature       | count |\n",
      "+--------------------+-------+\n",
      "|         y3         |  295  |\n",
      "|         y2         |  250  |\n",
      "|         z1         |  242  |\n",
      "|         z2         |  228  |\n",
      "|         z3         |  218  |\n",
      "|         x4         |  202  |\n",
      "|         x3         |  200  |\n",
      "|         x2         |  165  |\n",
      "|         z4         |  161  |\n",
      "|         y1         |  132  |\n",
      "|         y4         |  118  |\n",
      "|         x1         |  111  |\n",
      "|        age         |   39  |\n",
      "|       weight       |   24  |\n",
      "|  body_mass_index   |   21  |\n",
      "| how_tall_in_meters |   15  |\n",
      "+--------------------+-------+\n",
      "[16 rows x 2 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i_feats.print_rows(20) #gender not shown, but in test trials it was dead-last in importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##5. Feature Engineering:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ####First we convert non-numeric values into unique integers for Machine Learning friendliness\n",
    "- ####Next we consider that the acceleromer readings belong to 4 different sensors\n",
    "    -Sensor 1: x1, y2, z1\n",
    "    \n",
    "    -Sensor 2: x2, y2, z2\n",
    "    \n",
    "    -Sensor 3: x3, y3, z3\n",
    "    \n",
    "    -Sensor 4: x4, y4, z4\n",
    "    \n",
    "- ####We can calculate the latent features of Yaw and Pitch for each sensor using the following formulas\n",
    "    \n",
    "    -**Pitch, P =** atan( x / sqrt( y^2 + z^2 ) )\n",
    "    \n",
    "    -**Yaw, Y =** atan( y / sqrt( x^2 + z^2 ) )\n",
    "    \n",
    "    Source: [Freescale Semiconductor Document Number: AN3461 Application Note Rev. 6, 03/2013][df1]\n",
    "[df1]: <http://daringfireball.net/projects/markdown/>\n",
    "\n",
    "- ####Additionally the difference of Pitch and Roll between the devices has utility as they are mounted on different locations across the person wearing them. The relative difference between Yaw for sitting vs. standing for instance will be markedly different.\n",
    "    \n",
    "    -**n1n2PitchDiff =** Pitch_n1 - Pitch_n2 (for all devices n1 and n2 where n1 is not n2)\n",
    "    \n",
    "    -**n1n2RollDiff =** Roll_n1 - Roll_n2 (for all devices n1 and n2 where n1 is not n2)\n",
    "\n",
    "- ####Finally we perform Principal Component Analysis(PCA) to remove any co-linearity, and reduce the feature space down to a managable number of signifigant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_columns_to_unique_ints(data_frame):\n",
    "    '''\n",
    "    Accepts DataFrame object\n",
    "    Returns DataFrame where non-numeric values are given numeric values\n",
    "    '''\n",
    "    for col_name in ['user', 'gender', 'class']:\n",
    "        original_values = data_frame[col_name].unique()\n",
    "        new_values = range(len(original_values))\n",
    "        print \"converting\", original_values\n",
    "        print \"into......\", new_values\n",
    "        data_frame[col_name] = data_frame[col_name].replace(original_values, new_values)\n",
    "    return data_frame\n",
    "\n",
    "def pitch(x,y,z):\n",
    "    \"\"\"\n",
    "    Accepts accelerometer readings from a device and \n",
    "    Returns pitch angle\n",
    "    \"\"\"\n",
    "    return math.atan( x / math.sqrt( y**2 + z**2 ) )\n",
    "\n",
    "def roll(x,y,z):\n",
    "    \"\"\"\n",
    "    Accepts accelerometer readings from a device and \n",
    "    Returns roll angle\n",
    "    \"\"\"\n",
    "    return math.atan( y / math.sqrt( x**2 + z**2 ) )\n",
    "\n",
    "def add_pitch_roll(data_frame):\n",
    "    \"\"\"\n",
    "    Accepts DataFrame \n",
    "    Returns DataFrame with new columns for orientation angles\n",
    "    \"\"\"\n",
    "    result = data_frame.copy()\n",
    "    for i in range(1,5):\n",
    "        s = str(i)\n",
    "        result['pitch'+s] = np.vectorize(pitch)(result['x'+s], result['y'+s], result['z'+s])\n",
    "        result['roll'+s] = np.vectorize(roll)(result['x'+s], result['y'+s], result['z'+s])\n",
    "    return result\n",
    "\n",
    "def add_pitch_roll_diff(data_frame):\n",
    "    \"\"\"\n",
    "    Accepts DataFrame\n",
    "    Returns DataFrame with new columns for difference between orientation angles\n",
    "    \"\"\"\n",
    "    result = data_frame.copy()\n",
    "    for i in range(1,5):\n",
    "        for j in range(1,5):\n",
    "            s1, s2 = str(i), str(j)\n",
    "            if s1 != s2:\n",
    "                result['pitchdiff'+s1+s2] = np.vectorize(np.subtract)(result['pitch'+s1], result['pitch'+s2])\n",
    "                result['rolldiff'+s1+s2] = np.vectorize(np.subtract)(result['roll'+s1], result['roll'+s2])\n",
    "    return result\n",
    "\n",
    "def PCAIT(data_frame, n_features):\n",
    "    \"\"\"\n",
    "    Accepts DataFrame\n",
    "    Returns DataFrame which as been PCA reduced down to n_features\n",
    "    \"\"\"\n",
    "    result = data_frame.copy()\n",
    "    target = result.pop('class')\n",
    "    pca = PCA(n_components = n_features)\n",
    "    pca.fit(result)\n",
    "    result = pd.DataFrame(pca.transform(result))\n",
    "    result['class'] = target.astype(str)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ####Perform the conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converting ['debora' 'katia' 'wallace' 'jose_carlos']\n",
      "into...... [0, 1, 2, 3]\n",
      "converting ['Woman' 'Man']\n",
      "into...... [0, 1]\n",
      "converting ['sitting' 'sittingdown' 'standing' 'standingup' 'walking']\n",
      "into...... [0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "df = convert_columns_to_unique_ints(df) # convert columns with names into integer values\n",
    "df = add_pitch_roll(df)\n",
    "df = add_pitch_roll_diff(df)\n",
    "df_non_PCA = df.copy() # ignore this for now, we will use it on step 7\n",
    "df = PCAIT(df, n_features = 25) # 25 features are chosen because additional features showed diminishing returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ####Normalize the data and ensure the target is of type int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(df, target):\n",
    "    \"\"\"\n",
    "    Accepts DataFrame object and a target column\n",
    "    Returns DataFrame with normalized columns (target is not normalized)\n",
    "    \"\"\"\n",
    "    result = df.copy()\n",
    "    for feature_name in df.columns:\n",
    "        if feature_name != target:\n",
    "            max_value = df[feature_name].max()\n",
    "            min_value = df[feature_name].min()\n",
    "            result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = normalize(df, 'class' )\n",
    "df['class'] = df['class'].astype(float).fillna(0).astype(int)\n",
    "sf = gl.SFrame(data = df)   #turn DataFrame into GraphLab SFrame object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##6. Generate and tune model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ####Next we generate a new GradientBoostedTrees classifier using our engineered features and tune the following parameters using a grid_search to maximize accuracy:\n",
    "    -max_iterations\n",
    "    \n",
    "    -max_depth\n",
    "    \n",
    "    -step_size\n",
    "    \n",
    "    -column_subsample\n",
    "    \n",
    "    -row_subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n",
      "PROGRESS: Boosted trees classifier:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 141563\n",
      "PROGRESS: Number of classes           : 5\n",
      "PROGRESS: Number of feature columns   : 25\n",
      "PROGRESS: Number of unpacked features : 25\n",
      "PROGRESS: Starting Boosted Trees\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS:   Iter      Accuracy          Elapsed time\n",
      "PROGRESS:         (training) (validation)\n",
      "PROGRESS:      0   9.334e-01   9.289e-01        0.41s\n",
      "PROGRESS:      1   9.618e-01   9.558e-01        0.77s\n",
      "PROGRESS:      2   9.703e-01   9.640e-01        1.20s\n",
      "PROGRESS:      3   9.764e-01   9.726e-01        1.58s\n",
      "PROGRESS:      4   9.795e-01   9.750e-01        1.95s\n",
      "PROGRESS:      5   9.821e-01   9.780e-01        2.33s\n",
      "PROGRESS:      6   9.843e-01   9.809e-01        2.69s\n",
      "PROGRESS:      7   9.859e-01   9.822e-01        3.08s\n",
      "PROGRESS:      8   9.874e-01   9.838e-01        3.44s\n",
      "PROGRESS:      9   9.886e-01   9.855e-01        3.83s\n",
      "PROGRESS:     10   9.894e-01   9.865e-01        4.27s\n",
      "PROGRESS:     11   9.904e-01   9.873e-01        4.62s\n",
      "PROGRESS:     12   9.912e-01   9.886e-01        4.96s\n",
      "PROGRESS:     13   9.922e-01   9.890e-01        5.37s\n",
      "PROGRESS:     14   9.930e-01   9.897e-01        5.84s\n",
      "PROGRESS:     15   9.935e-01   9.904e-01        6.20s\n",
      "PROGRESS:     16   9.941e-01   9.905e-01        6.60s\n",
      "PROGRESS:     17   9.943e-01   9.908e-01        6.95s\n",
      "PROGRESS:     18   9.947e-01   9.915e-01        7.31s\n",
      "PROGRESS:     19   9.952e-01   9.919e-01        7.67s\n",
      "PROGRESS:     20   9.955e-01   9.924e-01        8.03s\n",
      "PROGRESS:     21   9.957e-01   9.931e-01        8.41s\n",
      "PROGRESS:     22   9.958e-01   9.931e-01        8.73s\n",
      "PROGRESS:     23   9.963e-01   9.935e-01        9.20s\n",
      "PROGRESS:     24   9.966e-01   9.938e-01        9.58s\n",
      "PROGRESS:     25   9.968e-01   9.939e-01        9.92s\n",
      "PROGRESS:     26   9.969e-01   9.942e-01       10.39s\n",
      "PROGRESS:     27   9.970e-01   9.942e-01       10.73s\n",
      "PROGRESS:     28   9.971e-01   9.942e-01       11.07s\n",
      "PROGRESS:     29   9.972e-01   9.942e-01       11.40s\n",
      "PROGRESS:     30   9.972e-01   9.942e-01       11.71s\n",
      "PROGRESS:     31   9.973e-01   9.945e-01       12.02s\n",
      "PROGRESS:     32   9.974e-01   9.946e-01       12.35s\n",
      "PROGRESS:     33   9.974e-01   9.946e-01       12.67s\n",
      "PROGRESS:     34   9.975e-01   9.943e-01       13.11s\n",
      "PROGRESS:     35   9.978e-01   9.949e-01       13.64s\n",
      "PROGRESS:     36   9.980e-01   9.953e-01       14.45s\n",
      "PROGRESS:     37   9.981e-01   9.954e-01       14.93s\n",
      "PROGRESS:     38   9.982e-01   9.954e-01       15.35s\n",
      "PROGRESS:     39   9.982e-01   9.951e-01       15.71s\n",
      "PROGRESS:     40   9.983e-01   9.951e-01       16.05s\n",
      "PROGRESS:     41   9.984e-01   9.951e-01       16.38s\n",
      "PROGRESS:     42   9.984e-01   9.953e-01       16.74s\n",
      "PROGRESS:     43   9.984e-01   9.953e-01       17.25s\n",
      "PROGRESS:     44   9.984e-01   9.954e-01       17.63s\n",
      "PROGRESS:     45   9.986e-01   9.955e-01       18.04s\n",
      "PROGRESS:     46   9.986e-01   9.958e-01       18.41s\n",
      "PROGRESS:     47   9.987e-01   9.959e-01       18.71s\n",
      "PROGRESS:     48   9.987e-01   9.959e-01       19.09s\n",
      "PROGRESS:     49   9.988e-01   9.958e-01       19.40s\n",
      "PROGRESS:     50   9.988e-01   9.958e-01       19.79s\n",
      "PROGRESS:     51   9.989e-01   9.961e-01       20.12s\n",
      "PROGRESS:     52   9.989e-01   9.959e-01       20.46s\n",
      "PROGRESS:     53   9.989e-01   9.959e-01       21.01s\n",
      "PROGRESS:     54   9.991e-01   9.961e-01       21.36s\n",
      "PROGRESS:     55   9.990e-01   9.961e-01       21.69s\n",
      "PROGRESS:     56   9.991e-01   9.962e-01       22.35s\n",
      "PROGRESS:     57   9.992e-01   9.961e-01       22.87s\n",
      "PROGRESS:     58   9.993e-01   9.962e-01       23.20s\n",
      "PROGRESS:     59   9.992e-01   9.961e-01       23.55s\n",
      "PROGRESS:     60   9.993e-01   9.963e-01       23.89s\n",
      "PROGRESS:     61   9.993e-01   9.961e-01       24.22s\n",
      "PROGRESS:     62   9.993e-01   9.962e-01       24.59s\n",
      "PROGRESS:     63   9.994e-01   9.961e-01       24.90s\n",
      "PROGRESS:     64   9.993e-01   9.962e-01       25.22s\n",
      "PROGRESS:     65   9.994e-01   9.961e-01       25.58s\n",
      "PROGRESS:     66   9.994e-01   9.961e-01       25.93s\n",
      "PROGRESS:     67   9.994e-01   9.961e-01       26.27s\n",
      "PROGRESS:     68   9.995e-01   9.962e-01       26.61s\n",
      "PROGRESS:     69   9.995e-01   9.963e-01       26.93s\n",
      "PROGRESS:     70   9.995e-01   9.962e-01       27.24s\n",
      "PROGRESS:     71   9.995e-01   9.963e-01       27.58s\n",
      "PROGRESS:     72   9.996e-01   9.963e-01       27.94s\n",
      "PROGRESS:     73   9.996e-01   9.965e-01       28.28s\n",
      "PROGRESS:     74   9.996e-01   9.966e-01       28.59s\n",
      "PROGRESS:     75   9.996e-01   9.965e-01       28.88s\n",
      "PROGRESS:     76   9.996e-01   9.965e-01       29.19s\n",
      "PROGRESS:     77   9.996e-01   9.966e-01       29.50s\n",
      "PROGRESS:     78   9.996e-01   9.966e-01       29.81s\n",
      "PROGRESS:     79   9.997e-01   9.966e-01       30.12s\n",
      "PROGRESS:     80   9.997e-01   9.968e-01       30.46s\n",
      "PROGRESS:     81   9.997e-01   9.968e-01       30.82s\n",
      "PROGRESS:     82   9.997e-01   9.968e-01       31.19s\n",
      "PROGRESS:     83   9.997e-01   9.966e-01       31.56s\n",
      "PROGRESS:     84   9.997e-01   9.965e-01       31.89s\n",
      "PROGRESS:     85   9.997e-01   9.966e-01       32.20s\n",
      "PROGRESS:     86   9.997e-01   9.965e-01       32.52s\n",
      "PROGRESS:     87   9.997e-01   9.965e-01       32.82s\n",
      "PROGRESS:     88   9.997e-01   9.968e-01       33.11s\n",
      "PROGRESS:     89   9.997e-01   9.968e-01       33.62s\n",
      "PROGRESS:     90   9.997e-01   9.968e-01       34.13s\n",
      "PROGRESS:     91   9.997e-01   9.969e-01       34.45s\n",
      "PROGRESS:     92   9.997e-01   9.968e-01       34.81s\n",
      "PROGRESS:     93   9.997e-01   9.969e-01       35.15s\n",
      "PROGRESS:     94   9.997e-01   9.969e-01       35.47s\n",
      "PROGRESS:     95   9.997e-01   9.970e-01       35.77s\n",
      "PROGRESS:     96   9.997e-01   9.970e-01       36.20s\n",
      "PROGRESS:     97   9.998e-01   9.970e-01       36.55s\n",
      "PROGRESS:     98   9.998e-01   9.969e-01       36.87s\n",
      "PROGRESS:     99   9.998e-01   9.970e-01       37.19s\n",
      "PROGRESS:    100   9.998e-01   9.969e-01       37.63s\n",
      "PROGRESS:    101   9.998e-01   9.969e-01       37.94s\n",
      "PROGRESS:    102   9.998e-01   9.969e-01       38.29s\n",
      "PROGRESS:    103   9.998e-01   9.969e-01       38.70s\n",
      "PROGRESS:    104   9.999e-01   9.969e-01       39.03s\n",
      "PROGRESS:    105   9.999e-01   9.969e-01       39.37s\n",
      "PROGRESS:    106   9.998e-01   9.970e-01       40.32s\n",
      "PROGRESS:    107   9.999e-01   9.970e-01       41.11s\n",
      "PROGRESS:    108   9.999e-01   9.969e-01       41.73s\n",
      "PROGRESS:    109   9.999e-01   9.969e-01       42.10s\n",
      "PROGRESS:    110   9.999e-01   9.969e-01       42.79s\n",
      "PROGRESS:    111   9.999e-01   9.970e-01       43.50s\n",
      "PROGRESS:    112   9.999e-01   9.970e-01       43.82s\n",
      "PROGRESS:    113   9.999e-01   9.970e-01       44.63s\n",
      "PROGRESS:    114   9.999e-01   9.969e-01       44.95s\n",
      "PROGRESS:    115   9.999e-01   9.970e-01       45.33s\n",
      "PROGRESS:    116   9.999e-01   9.970e-01       45.64s\n",
      "PROGRESS:    117   9.999e-01   9.970e-01       45.97s\n",
      "PROGRESS:    118   9.999e-01   9.970e-01       46.31s\n",
      "PROGRESS:    119   9.999e-01   9.969e-01       46.62s\n",
      "PROGRESS:    120   9.999e-01   9.970e-01       46.94s\n",
      "PROGRESS:    121   9.999e-01   9.969e-01       47.30s\n",
      "PROGRESS:    122   9.999e-01   9.970e-01       47.62s\n",
      "PROGRESS:    123   9.999e-01   9.970e-01       47.93s\n",
      "PROGRESS:    124   9.999e-01   9.970e-01       48.27s\n",
      "PROGRESS:    125   9.999e-01   9.970e-01       48.59s\n",
      "PROGRESS:    126   9.999e-01   9.970e-01       48.93s\n",
      "PROGRESS:    127   9.999e-01   9.970e-01       49.24s\n",
      "PROGRESS:    128   9.999e-01   9.970e-01       49.58s\n",
      "PROGRESS:    129   1.000e+00   9.970e-01       49.88s\n",
      "PROGRESS:    130   1.000e+00   9.970e-01       50.17s\n",
      "PROGRESS:    131   1.000e+00   9.970e-01       50.48s\n",
      "PROGRESS:    132   1.000e+00   9.970e-01       50.79s\n",
      "PROGRESS:    133   1.000e+00   9.970e-01       51.42s\n",
      "PROGRESS:    134   1.000e+00   9.970e-01       51.72s\n",
      "PROGRESS:    135   1.000e+00   9.970e-01       52.03s\n",
      "PROGRESS:    136   1.000e+00   9.970e-01       52.31s\n",
      "PROGRESS:    137   1.000e+00   9.970e-01       52.62s\n",
      "PROGRESS:    138   1.000e+00   9.970e-01       52.93s\n",
      "PROGRESS:    139   1.000e+00   9.970e-01       53.24s\n",
      "PROGRESS:    140   1.000e+00   9.970e-01       53.55s\n",
      "PROGRESS:    141   1.000e+00   9.970e-01       53.85s\n",
      "PROGRESS:    142   1.000e+00   9.970e-01       54.13s\n",
      "PROGRESS:    143   1.000e+00   9.970e-01       54.47s\n",
      "PROGRESS:    144   1.000e+00   9.970e-01       54.80s\n",
      "PROGRESS:    145   1.000e+00   9.970e-01       55.11s\n",
      "PROGRESS:    146   1.000e+00   9.970e-01       55.42s\n",
      "PROGRESS:    147   1.000e+00   9.970e-01       55.72s\n",
      "PROGRESS:    148   1.000e+00   9.970e-01       56.17s\n",
      "PROGRESS:    149   1.000e+00   9.970e-01       56.48s\n",
      "PROGRESS:    150   1.000e+00   9.970e-01       56.83s\n",
      "PROGRESS:    151   1.000e+00   9.970e-01       57.13s\n",
      "PROGRESS:    152   1.000e+00   9.970e-01       57.42s\n",
      "PROGRESS:    153   1.000e+00   9.970e-01       57.72s\n",
      "PROGRESS:    154   1.000e+00   9.970e-01       58.01s\n",
      "PROGRESS:    155   1.000e+00   9.970e-01       58.32s\n",
      "PROGRESS:    156   1.000e+00   9.970e-01       58.60s\n",
      "PROGRESS:    157   1.000e+00   9.969e-01       58.91s\n",
      "PROGRESS:    158   1.000e+00   9.970e-01       59.19s\n",
      "PROGRESS:    159   1.000e+00   9.970e-01       59.61s\n",
      "PROGRESS:    160   1.000e+00   9.970e-01       59.94s\n",
      "PROGRESS:    161   1.000e+00   9.970e-01       60.27s\n",
      "PROGRESS:    162   1.000e+00   9.970e-01       60.58s\n",
      "PROGRESS:    163   1.000e+00   9.969e-01       60.88s\n",
      "PROGRESS:    164   1.000e+00   9.970e-01       61.17s\n",
      "PROGRESS:    165   1.000e+00   9.970e-01       61.46s\n",
      "PROGRESS:    166   1.000e+00   9.970e-01       61.83s\n",
      "PROGRESS:    167   1.000e+00   9.970e-01       62.17s\n",
      "PROGRESS:    168   1.000e+00   9.970e-01       62.64s\n",
      "PROGRESS:    169   1.000e+00   9.970e-01       62.94s\n"
     ]
    }
   ],
   "source": [
    "train, test = sf.random_split(.9)  #randomly choose 10% of the data and set aside for model verification\n",
    "model = gl.boosted_trees_classifier.create(train, target='class', column_subsample=.55, max_depth=9, \n",
    "                                           max_iterations=170, min_child_weight=8, min_loss_reduction=0,\n",
    "                                           row_subsample=.85, step_size=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ####Finally we inspect our new model and see that the accuracy of our classification has risen to ~99.65%\n",
    "  \n",
    "  - This is a rise of 3.5% over the best models performance from page 9 of the Presentation shown in the opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'confusion_matrix': Columns:\n",
      "\ttarget_label\tint\n",
      "\tpredicted_label\tint\n",
      "\tcount\tint\n",
      "\n",
      "Rows: 17\n",
      "\n",
      "Data:\n",
      "+--------------+-----------------+-------+\n",
      "| target_label | predicted_label | count |\n",
      "+--------------+-----------------+-------+\n",
      "|      3       |        3        |  1271 |\n",
      "|      3       |        0        |   4   |\n",
      "|      3       |        1        |   7   |\n",
      "|      2       |        4        |   9   |\n",
      "|      3       |        2        |   5   |\n",
      "|      4       |        3        |   2   |\n",
      "|      4       |        2        |   3   |\n",
      "|      0       |        0        |  5151 |\n",
      "|      3       |        4        |   1   |\n",
      "|      1       |        1        |  1160 |\n",
      "+--------------+-----------------+-------+\n",
      "[17 rows x 3 columns]\n",
      "Note: Only the head of the SFrame is printed.\n",
      "You can use print_rows(num_rows=m, num_columns=n) to print more rows and columns., 'accuracy': 0.9968811851496432}\n"
     ]
    }
   ],
   "source": [
    "print model.evaluate(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ####We can go on to show that this model uses more of its feature space than the default model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff89c122e10>]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEACAYAAAC08h1NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff89cca4410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i_feats = model.get_feature_importance()\n",
    "f_imps = i_feats['count']\n",
    "plt.plot(f_imps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+\n",
      "| feature | count |\n",
      "+---------+-------+\n",
      "|    3    |  1157 |\n",
      "|    11   |  1151 |\n",
      "|    5    |  1137 |\n",
      "|    6    |  1131 |\n",
      "|    24   |  1126 |\n",
      "|    1    |  1099 |\n",
      "|    9    |  1073 |\n",
      "|    4    |  1073 |\n",
      "|    0    |  1037 |\n",
      "|    2    |  1030 |\n",
      "|    15   |  1005 |\n",
      "|    7    |  985  |\n",
      "|    17   |  958  |\n",
      "|    23   |  824  |\n",
      "|    12   |  791  |\n",
      "|    13   |  785  |\n",
      "|    14   |  784  |\n",
      "|    16   |  758  |\n",
      "+---------+-------+\n",
      "[25 rows x 2 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i_feats.print_rows(18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ####Since PCA precludes interpretability of the features, we can run the experiment again without PCA just to see what features are important and gain a little insight into our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##7. Examine Feature Space:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ####Using the df_non_PCA we set aside from step 5, let's see what features were important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_non_PCA = normalize(df_non_PCA, 'class' )\n",
    "df_non_PCA['class'] = df_non_PCA['class'].astype(float).fillna(0).astype(int)\n",
    "sf_non_PCA = gl.SFrame(data = df_non_PCA)   #turn DataFrame into GraphLab SFrame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROGRESS: Creating a validation set from 5 percent of training data. This may take a while.\n",
      "          You can set ``validation_set=None`` to disable validation tracking.\n",
      "\n",
      "PROGRESS: The following methods are available for this type of problem.\n",
      "PROGRESS: BoostedTreesClassifier, RandomForestClassifier, LogisticClassifier\n",
      "PROGRESS: The returned model will be chosen according to validation accuracy.\n",
      "PROGRESS: Boosted trees classifier:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 157322\n",
      "PROGRESS: Number of classes           : 5\n",
      "PROGRESS: Number of feature columns   : 50\n",
      "PROGRESS: Number of unpacked features : 50\n",
      "PROGRESS: Starting Boosted Trees\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS:   Iter      Accuracy          Elapsed time\n",
      "PROGRESS:         (training) (validation)\n",
      "PROGRESS:      0   9.414e-01   9.425e-01        0.73s\n",
      "PROGRESS:      1   9.530e-01   9.546e-01        1.45s\n",
      "PROGRESS:      2   9.605e-01   9.602e-01        2.10s\n",
      "PROGRESS:      3   9.658e-01   9.653e-01        2.79s\n",
      "PROGRESS:      4   9.697e-01   9.698e-01        3.45s\n",
      "PROGRESS:      5   9.738e-01   9.729e-01        4.10s\n",
      "PROGRESS:      6   9.764e-01   9.767e-01        4.77s\n",
      "PROGRESS:      7   9.781e-01   9.785e-01        5.45s\n",
      "PROGRESS:      8   9.800e-01   9.788e-01        6.13s\n",
      "PROGRESS:      9   9.819e-01   9.811e-01        6.77s\n",
      "PROGRESS: Random forest classifier:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 157322\n",
      "PROGRESS: Number of classes           : 5\n",
      "PROGRESS: Number of feature columns   : 50\n",
      "PROGRESS: Number of unpacked features : 50\n",
      "PROGRESS: Starting Boosted Trees\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS:   Iter      Accuracy          Elapsed time\n",
      "PROGRESS:         (training) (validation)\n",
      "PROGRESS:      0   9.441e-01   9.450e-01        0.64s\n",
      "PROGRESS:      1   9.444e-01   9.449e-01        1.09s\n",
      "PROGRESS:      2   9.452e-01   9.481e-01        1.57s\n",
      "PROGRESS:      3   9.467e-01   9.495e-01        2.01s\n",
      "PROGRESS:      4   9.473e-01   9.496e-01        2.49s\n",
      "PROGRESS:      5   9.483e-01   9.499e-01        2.97s\n",
      "PROGRESS:      6   9.478e-01   9.496e-01        3.49s\n",
      "PROGRESS:      7   9.482e-01   9.501e-01        3.98s\n",
      "PROGRESS:      8   9.490e-01   9.509e-01        4.44s\n",
      "PROGRESS:      9   9.495e-01   9.511e-01        5.02s\n",
      "PROGRESS: Logistic regression:\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: Number of examples          : 157322\n",
      "PROGRESS: Number of classes           : 5\n",
      "PROGRESS: Number of feature columns   : 50\n",
      "PROGRESS: Number of unpacked features : 50\n",
      "PROGRESS: Number of coefficients    : 204\n",
      "PROGRESS: Starting Newton Method\n",
      "PROGRESS: --------------------------------------------------------\n",
      "PROGRESS: +-----------+----------+--------------+-------------------+---------------------+\n",
      "PROGRESS: | Iteration | Passes   | Elapsed Time | Training-accuracy | Validation-accuracy |\n",
      "PROGRESS: +-----------+----------+--------------+-------------------+---------------------+\n",
      "PROGRESS: | 1         | 2        | 1.693003     | 0.831893          | 0.832732            |\n",
      "PROGRESS: | 2         | 3        | 2.544757     | 0.868810          | 0.868111            |\n",
      "PROGRESS: | 3         | 4        | 3.378895     | 0.886875          | 0.887244            |\n",
      "PROGRESS: | 4         | 5        | 4.205652     | 0.897262          | 0.896992            |\n",
      "PROGRESS: | 5         | 6        | 5.037709     | 0.901451          | 0.900000            |\n",
      "PROGRESS: | 6         | 7        | 5.888723     | 0.903021          | 0.901685            |\n",
      "PROGRESS: | 10        | 11       | 9.374957     | 0.903593          | 0.902527            |\n",
      "PROGRESS: +-----------+----------+--------------+-------------------+---------------------+\n",
      "PROGRESS: Model selection based on validation accuracy:\n",
      "PROGRESS: ---------------------------------------------\n",
      "PROGRESS: BoostedTreesClassifier          : 0.98110709988\n",
      "PROGRESS: RandomForestClassifier          : 0.951143200963\n",
      "PROGRESS: LogisticClassifier              : 0.902527\n",
      "PROGRESS: ---------------------------------------------\n",
      "PROGRESS: Selecting BoostedTreesClassifier based on validation set performance.\n"
     ]
    }
   ],
   "source": [
    "model = gl.classifier.create(sf_non_PCA, target='class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ####Print most signifigant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|  feature   | count |\n",
      "+------------+-------+\n",
      "|     y3     |  203  |\n",
      "|     z2     |  160  |\n",
      "|     y2     |  151  |\n",
      "|     z1     |  138  |\n",
      "|     z3     |  116  |\n",
      "|     z4     |  113  |\n",
      "|     y1     |   93  |\n",
      "|   roll3    |   87  |\n",
      "|     x4     |   84  |\n",
      "|   roll2    |   74  |\n",
      "|     x2     |   66  |\n",
      "|   pitch4   |   60  |\n",
      "|   pitch3   |   57  |\n",
      "|    user    |   56  |\n",
      "|   roll4    |   52  |\n",
      "|    age     |   51  |\n",
      "|     x3     |   49  |\n",
      "|     y4     |   48  |\n",
      "|     x1     |   48  |\n",
      "|   pitch1   |   44  |\n",
      "|   pitch2   |   39  |\n",
      "| rolldiff31 |   38  |\n",
      "| rolldiff13 |   37  |\n",
      "| rolldiff23 |   35  |\n",
      "|   roll1    |   34  |\n",
      "+------------+-------+\n",
      "[50 rows x 2 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i_feats = model.get_feature_importance()\n",
    "f_imps = i_feats['count']\n",
    "i_feats.print_rows(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#8. Conclusion:\n",
    " - ###Engineering Features Roll/Pitch took us from 96% to 98% accuracy (Step 5)\n",
    " - ###PCA took us from 98% to 99.6% accuracy (Step 6)\n",
    " - ###Roll/Pitch-Difference seem to be less signifigant but was still useful\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
